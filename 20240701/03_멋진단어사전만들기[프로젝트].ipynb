{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18827fed",
   "metadata": {},
   "source": [
    "## 3-1. 프로젝트: SentencePiece 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b42891e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "3.4.3\n",
      "0.5.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import konlpy\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(plt.__version__)\n",
    "print(konlpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8210135d",
   "metadata": {},
   "source": [
    "#### Step 1. SentencePiece 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "011d7117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6967122",
   "metadata": {},
   "source": [
    "## Step 2. SentencePiece 설치하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2472805e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/3482574838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_corpus\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# 이전 스텝에서 정제했던 corpus를 활용.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있음.\n",
    "# --model_type = 'bpe' 로 옵션을 주어 변경할 수 있음.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a5b41b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Not found: \"korean_spm.model\": No such file or directory Error #2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/444265515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'korean_spm.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# SentencePiece를 활용한 sentence -> encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokensIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncodeAsIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'아버지가방에들어가신다.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mLoad\u001b[0;34m(self, model_file, model_proto)\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodel_proto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromSerializedProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mLoadFromFile\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor_LoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDecodeIdsWithCheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Not found: \"korean_spm.model\": No such file or directory Error #2"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e10cef",
   "metadata": {},
   "source": [
    "## Step 3. Tokenizer 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c9ec995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b21ceaa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './korean_spm.vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33/2775304834.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmy_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'나는 밥을 먹었습니다.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'그러나 여전히 ㅠㅠ 배가 고픕니다...'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(word_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_33/2828170821.py\u001b[0m in \u001b[0;36msp_tokenize\u001b[0;34m(s, corpus)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncodeAsIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./korean_spm.vocab\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './korean_spm.vocab'"
     ]
    }
   ],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)\n",
    "# print(word_index)\n",
    "# print(index_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f8fe8",
   "metadata": {},
   "source": [
    "## Step 4. 네이버 영화리뷰 감정분석 문제에 SentencePiece 적용해 보기\n",
    "\n",
    "- [네이버 영화리뷰 감정분석 태스크](https://github.com/e9t/nsmc/)\n",
    "- 한국어로 된 코퍼스를 다루어야 하므로 주로 KoNLPy에서 제공하는 형태소 분석기를 사용하여 텍스트를 전저치래서 RNN 모델을 분류기로 사용했을 것이다.\n",
    "- 만약 이 문제에서 tokenizer를 sentencepiece로 바꿔 다시 풀어본다면 성능이 좋아질지 비교해보자.\n",
    "\n",
    "> - 네이버 영화리뷰 감정분석 코퍼스에 sentencepiece를 적용시킨 모델 학습하기\n",
    "> - 학습된 모델로 sp_tokenize() 메소드 구현하기\n",
    "> - 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정분석 모델을 재학습하기\n",
    "> - KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
    "> - (보너스) SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기\n",
    "> - Word Vector는 활용할 필요가 없고 활용이 가능하지도 않을 것이다.\n",
    "> - 머지 않아 SentencePiece와 BERT 등의 pretrained 모델을 함께 활용하는 태스크를 다루게 될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c92cf260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-01 06:50:56--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [text/plain]\n",
      "Saving to: ‘ratings_train.txt’\n",
      "\n",
      "ratings_train.txt   100%[===================>]  13.95M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2024-07-01 06:50:56 (174 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n",
      "\n",
      "--2024-07-01 06:50:57--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [application/octet-stream]\n",
      "Saving to: ‘ratings_test.txt’\n",
      "\n",
      "ratings_test.txt    100%[===================>]   4.67M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2024-07-01 06:50:58 (79.8 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
    "!mv ratings_*.txt ~/aiffel/sp_tokenizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56afad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 사이즈: 150000\n",
      "test 데이터 사이즈: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어오기\n",
    "train_data = pd.read_table('~/aiffel/sp_tokenizer/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sp_tokenizer/data/ratings_test.txt')\n",
    "\n",
    "print('train 데이터 사이즈:', len(train_data))\n",
    "print('test 데이터 사이즈:', len(test_data))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43b4f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 사이즈: 146182\n",
      "test 데이터 사이즈: 49157\n"
     ]
    }
   ],
   "source": [
    "# 중복 및 결측치 제거\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "train_data = train_data.dropna(how = 'any') \n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "print('train 데이터 사이즈:', len(train_data))\n",
    "print('test 데이터 사이즈:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "486db18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 195339\n",
      "Example:\n",
      ">> 아 더빙.. 진짜 짜증나네요 목소리\n",
      ">> 나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님\n",
      ">> 단순하면서 은은한 매력의 영화\n",
      ">> 보는내내 그대로 들어맞는 예측 카리스마 없는 악역\n",
      ">> 뭐냐..시작하고 3분만에 나왔다. 리플릿 사진 보며 불안하더니만..\n"
     ]
    }
   ],
   "source": [
    "data = list(train_data['document']) + list(test_data['document'])\n",
    "\n",
    "print(\"Data Size:\", len(data))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in data[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce0edd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33/4031225536.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbFklEQVR4nO3df5hdVX3v8fdHwi9BSQIxhkyuE0uUBp+KOEKo3JZrND9ACPWxNJZKxPTJ9T60F3uxmMB9jCJXofWK0IvQVCKBUkIaRSJEcQz43GstyEQg/AhpRglkQkIG8oNfFgl87x97Hbozzo8zyZlzzsz6vJ7nPLP32uuss/Y6c7577bV/KSIwM7M8vKnRFTAzs/px0Dczy4iDvplZRhz0zcwy4qBvZpYRB30zs4w46JvVmKRWSSFpVA3LPEfSj2pY3qOSTk3TX5T0jzUs+2JJ36pVeVZbDvojnKRTJP1M0m5JOyT9i6QP1KDcT0n6aS3qWEuSNkn68HD6TEk3SPqNpBfS6xFJX5V0RCVPRNwcETOqLOuygfJFxHER8ZN9rXPp806V1NWj7K9ExJ/vb9k2NBz0RzBJbwXuAP4OGAtMBL4EvNLIelmv/iYi3gKMA84DpgH/IumwWn5ILfc+bHhy0B/Z3gUQEbdExGsR8euI+FFErKtkkPRpSesl7ZR0l6R3lJaFpM9I2ihpl6RrVPhd4DrgZEkvStqV8h8s6WuSnpL0jKTrJB2alp0qqUvShZK2S9oq6bzSZx0q6X9LejLtlfy09N5paW9ll6SHKsMSgyHpTZIWSvqlpOckrZA0Ni2rDMfMS3V/VtIlPeq2LLXRekkXVXq3km4C/hPw/dQWF5U+9pzeyutPRPx7RNwPnAkcSbEB2GvPKn0HV6Z2fF7Sw5LeI2kBcA5wUarL91P+TZI+L2kd8JKkUb3snRwi6da0p/ELSe8trX9IOqY0f4Oky9IG6QfA0enzXpR0tHoMF0k6U8Vw0i5JP0n/P5VlmyR9TtK69L3fKumQatrK9o2D/sj2b8BrKWDNljSmvFDSHOBi4GMUPcz/B9zSo4yPAh8Afg84G5gZEeuBzwD/GhGHR8TolPdyig3N8cAxFHsWXyiV9XbgiJQ+H7imVKevAe8Hfp9ir+Qi4HVJE4E7gctS+ueA70gaN8i2+EvgLOAPgaOBncA1PfKcArwbmA58oRScFgOtwDuBjwB/VnlDRHwSeAo4I7XF31RR3oAi4gWgHfjPvSyeAfwBRVsfQfG9PBcRS4CbKfYaDo+IM0rv+QRwOjA6Ivb0UuYc4J8p2vifgO9JOnCAOr4EzAaeTp93eEQ8Xc4j6V0U/1OfpfgfW02xgTyolO1sYBYwmeL/7FP9fa7tHwf9ESwinqcIPAH8A9AtaZWk8SnLZ4CvRsT6FAi+Ahxf7u0Dl0fEroh4CriHIqD/FkkCFgB/FRE7UtD6CjC3lO1V4NKIeDUiVgMvAu+W9Cbg08AFEbEl7ZX8LCJeoQiwqyNidUS8HhHtQAdw2iCb4zPAJRHRlcr9IvBx7T3c8aW0N/QQ8BBQ6e2eDXwlInZGRBdwdZWf2Vd51XqaIgj39CrwFuBYQOn72zpAWVdHxOaI+HUfy9dGxMqIeBX4OnAIxRDT/voT4M6IaE9lfw04lGLjXq7b0xGxA/g+ffyPWW046I9wKSB8KiJagPdQ9HK/kRa/A7gq7XbvAnYAouiJV2wrTb8MHN7HR40D3gysLZX3w5Re8VyPXmalvKMogswveyn3HcAfV8pM5Z4CTOhvvfso57ZSGeuB14DxpTx9revRwObSsvJ0f6ptu75MpPhO9hIRdwP/h2JPZbukJSqO3/RnoDq/sTwiXge6KNZ7fx0NPNmj7M3s2/+Y1YCDfkYi4nHgBorgD8WP779GxOjS69CI+Fk1xfWYfxb4NXBcqawjIqKaH/CzwL8Dv9PLss3ATT3qeFhEXF5FuT3Lmd2jnEMiYksV790KtJTmJ/VYXvNb1Uo6HPgwxZDbb4mIqyPi/cBUimGevx6gLgPV8Y11SnteLRR7GlAE4jeX8r59EOU+TbHBrZSt9FnVtLsNAQf9EUzSsenAaUuan0QxtntvynIdsEjScWn5EZL+uMrinwFaKmOzqQf3D8CVkt6WypsoaeZABaX3LgW+ng4EHiDpZEkHA/8InCFpZko/RMVB4ZZ+ijww5au8RqV1/V+VoStJ49IxjWqsoGinMekYw1/00hbvrLKsfqk4GP5+4HsUxx2+3UueD0g6KY25v0SxwXx9P+vyfkkfS231WYozvCr/Jw8Cf5rafxbFcZGKZ4AjVTq9tIcVwOmSpqf6XpjKrqZjYUPAQX9kewE4CbhP0ksUP+JHKH54RMRtwBXAcknPp2Wzqyz7buBRYJukZ1Pa54FO4N5U3o8pDmRW43PAw8D9FEMaVwBviojNFAcZLwa6KXrsf03//7urKfY6Kq8vAlcBq4AfSXqBoi1OqrJul1IMdzyR1mkle5/2+lXgf6aho89VWWZPF6V6PQfcCKwFfj8dLO3prRQb2J0UQyfPAX+bll0PTE11+d4gPv92ivH3ncAngY+lMXiAC4AzgF0UZwe9UW7ae7wF+FX6zL2GhCJiA8Vxmb+j2KM7g+Kg928GUTerIfkhKmaDI+m/AXMj4g8HzGzWZNzTNxuApAmSPqjiXP93U+wp3dboepntC1+dZzawg4C/pziPfBewHPhmIytktq88vGNmlhEP75iZZaSph3eOOuqoaG1tbXQ1zMyGlbVr1z4bEb3eqqSpg35raysdHR2NroaZ2bAi6cm+lnl4x8wsIw76ZmYZcdA3M8uIg76ZWUYc9M3MMlJV0Jc0WtJKSY+reFzcyZLGSmpX8Si99soTkFS4WlJnegTaCaVy5qX8GyXNG6qVMjOz3lXb078K+GFEHEvx9J/1wEJgTURMAdakeSju0jglvRYA1wKoeB7pYoo7G54ILO75+D4zMxtaAwb9dJ/sP6C4ZSsR8ZuI2EVxu9tlKdsyiuePktJvjMK9wGhJE4CZQHt6lN5Oiud/zqrhupiZ2QCq6elPpriP+bclPSDpW5IOA8aXnsu5jf947NxE9n40W1dK6yt9L5IWSOqQ1NHd3T24tTEzs35VE/RHAScA10bE+yie1LOwnCGKu7bV5M5tEbEkItoiom3cuF6vIm4qrQvvpHXhnY2uhplZVaoJ+l1AV0Tcl+ZXUmwEnknDNqS/29PyLez9DNGWlNZXupmZ1cmAQT8itgGb08MjAKYDj1E8eq5yBs48isetkdLPTWfxTAN2p2Ggu4AZ6TmjY4AZKc3MzOqk2huu/SVwc3oI9q+A8yg2GCskzad4TufZKe9q4DSKZ6W+nPISETskfZniGagAl0bEjpqshZmZVaWpH6LS1tYWzX6XzZ7j+ZsuP71BNTEzK0haGxFtvS3zFblmZhlx0Dczy4iDvplZRhz0zcwy0tSPS2xWvhjLzIYr9/TNzDLioG9mlhEHfTOzjDjom5llxEHfzCwjDvpmZhlx0K8x31/fzJqZg76ZWUYc9M3MMuKgb2aWEQd9M7OMOOibmWXEQd/MLCMO+mZmGXHQNzPLiIP+EPFFWmbWjBz0zcwy4qBvZpYRB30zs4w46JuZZcRB38wsI1UFfUmbJD0s6UFJHSltrKR2SRvT3zEpXZKultQpaZ2kE0rlzEv5N0qaNzSrZGZmfRlMT/+/RMTxEdGW5hcCayJiCrAmzQPMBqak1wLgWig2EsBi4CTgRGBxZUNhZmb1sT/DO3OAZWl6GXBWKf3GKNwLjJY0AZgJtEfEjojYCbQDs/bj883MbJCqDfoB/EjSWkkLUtr4iNiaprcB49P0RGBz6b1dKa2v9L1IWiCpQ1JHd3d3ldVrXr5Iy8yayagq850SEVskvQ1ol/R4eWFEhKSoRYUiYgmwBKCtra0mZZqZWaGqnn5EbEl/twO3UYzJP5OGbUh/t6fsW4BJpbe3pLS+0rPgHr+ZNYMBg76kwyS9pTINzAAeAVYBlTNw5gG3p+lVwLnpLJ5pwO40DHQXMEPSmHQAd0ZKMzOzOqlmeGc8cJukSv5/iogfSrofWCFpPvAkcHbKvxo4DegEXgbOA4iIHZK+DNyf8l0aETtqtiZmZjagAYN+RPwKeG8v6c8B03tJD+D8PspaCiwdfDXNzKwWfEWumVlGHPTrzAd0zayRHPTNzDLioG9mlhEHfTOzjDjom5llxEHfzCwjDvoN4rN4zKwRHPTNzDLioG9mlhEH/QbzMI+Z1ZODvplZRqp9iIqBe+RmNuy5p98kPMxjZvXgoG9mlhEHfTOzjDjom5llxEHfzCwjDvpmZhlx0G8yPovHzIaSg76ZWUYc9M3MMuKgb2aWEQd9M7OM+N47Tap8MHfT5ac3sCZmNpJU3dOXdICkByTdkeYnS7pPUqekWyUdlNIPTvOdaXlrqYxFKX2DpJk1XxszM+vXYIZ3LgDWl+avAK6MiGOAncD8lD4f2JnSr0z5kDQVmAscB8wCvinpgP2rfh58GqeZ1UpVQV9SC3A68K00L+BDwMqUZRlwVpqek+ZJy6en/HOA5RHxSkQ8AXQCJ9ZgHczMrErV9vS/AVwEvJ7mjwR2RcSeNN8FTEzTE4HNAGn57pT/jfRe3vMGSQskdUjq6O7urn5NzMxsQAMGfUkfBbZHxNo61IeIWBIRbRHRNm7cuHp85LDhYR4z21/VnL3zQeBMSacBhwBvBa4CRksalXrzLcCWlH8LMAnokjQKOAJ4rpReUX6PmZnVwYA9/YhYFBEtEdFKcSD27og4B7gH+HjKNg+4PU2vSvOk5XdHRKT0uensnsnAFODnNVsTMzMb0P6cp/95YLmky4AHgOtT+vXATZI6gR0UGwoi4lFJK4DHgD3A+RHx2n58vpmZDZKKTnhzamtri46OjkZX4w3NNp7ui7bMrDeS1kZEW2/LfBsGM7OMOOgPYz6bx8wGy0HfzCwjDvojgHv8ZlYtB30zs4w46JuZZcRBfwTxMI+ZDcRB38wsIw76ZmYZcdA3M8uIn5E7AvUc1/ftGsyswj19M7OMOOibmWXEQd/MLCMO+mZmGfGB3Cr4giczGync0zczy4h7+hnwKZxmVuGevplZRhz0zcwy4qBvZpYRB30zs4w46JuZZcRB38wsIw76ZmYZcdA3M8vIgEFf0iGSfi7pIUmPSvpSSp8s6T5JnZJulXRQSj84zXem5a2lshal9A2SZg7ZWpmZWa+quSL3FeBDEfGipAOBn0r6AfA/gCsjYrmk64D5wLXp786IOEbSXOAK4E8kTQXmAscBRwM/lvSuiHhtCNbL+lG+QtdX55rlZcCefhReTLMHplcAHwJWpvRlwFlpek6aJy2fLkkpfXlEvBIRTwCdwIm1WAkzM6tOVWP6kg6Q9CCwHWgHfgnsiog9KUsXMDFNTwQ2A6Tlu4Ejy+m9vKf8WQskdUjq6O7uHvQKmZlZ36oK+hHxWkQcD7RQ9M6PHaoKRcSSiGiLiLZx48YN1ceYmWVpUGfvRMQu4B7gZGC0pMoxgRZgS5reAkwCSMuPAJ4rp/fyHjMzq4Nqzt4ZJ2l0mj4U+AiwniL4fzxlmwfcnqZXpXnS8rsjIlL63HR2z2RgCvDzGq2HmZlVoZqzdyYAyyQdQLGRWBERd0h6DFgu6TLgAeD6lP964CZJncAOijN2iIhHJa0AHgP2AOf7zB0zs/pS0QlvTm1tbdHR0dHoamTxuMS+Tt2srLtP7TQbPiStjYi23pb5ilwzs4w46JuZZcTPyLVe5TCkZZYjB30DHOTNcuHhHTOzjDjom5llxEHfzCwjDvq2X1oX3unjAWbDiIO+1YSDv9nw4KBvZpYRB30zs4w46JuZZcQXZ1lVPF5vNjI46PfDgc7MRhoP75iZZcRB38wsIw76ZmYZcdA3M8uID+T2wgdwzWykck/fzCwj7umXuIe///wgdbPm5p6+mVlGHPTNzDLioG9mlhEHfTOzjAwY9CVNknSPpMckPSrpgpQ+VlK7pI3p75iULklXS+qUtE7SCaWy5qX8GyXNG7rVMjOz3lTT098DXBgRU4FpwPmSpgILgTURMQVYk+YBZgNT0msBcC0UGwlgMXAScCKwuLKhMDOz+hgw6EfE1oj4RZp+AVgPTATmAMtStmXAWWl6DnBjFO4FRkuaAMwE2iNiR0TsBNqBWbVcGTMz69+gxvQltQLvA+4DxkfE1rRoGzA+TU8ENpfe1pXS+ko3M7M6qTroSzoc+A7w2Yh4vrwsIgKIWlRI0gJJHZI6uru7a1GkmZklVV2RK+lAioB/c0R8NyU/I2lCRGxNwzfbU/oWYFLp7S0pbQtwao/0n/T8rIhYAiwBaGtrq8mGZCC+EtfMclHN2TsCrgfWR8TXS4tWAZUzcOYBt5fSz01n8UwDdqdhoLuAGZLGpAO4M1KamZnVSTU9/Q8CnwQelvRgSrsYuBxYIWk+8CRwdlq2GjgN6AReBs4DiIgdkr4M3J/yXRoRO2qxEmZmVp0Bg35E/BRQH4un95I/gPP7KGspsHQwFTQzs9rxFblmZhlx0Dczy4iDvplZRhz0zcwy4qBvZpYRB30zs4z4Gbk2JMpXOft5uWbNwz19M7OMOOibmWXEQd/MLCNZj+n77ppmlhv39M3MMuKgb2aWEQd9M7OMOOibmWXEQd/MLCMO+mZmGXHQNzPLSJbn6fv8fDPLlXv6NuRaF97pDa1lqRn/9x30zcwy4qBvZpYRB30zs4w46JuZZcRB38wsIw76ZmYZGTDoS1oqabukR0ppYyW1S9qY/o5J6ZJ0taROSesknVB6z7yUf6OkeUOzOtbMmvH0NbPcVNPTvwGY1SNtIbAmIqYAa9I8wGxgSnotAK6FYiMBLAZOAk4EFlc2FGZmVj8DBv2I+L/Ajh7Jc4BlaXoZcFYp/cYo3AuMljQBmAm0R8SOiNgJtPPbGxIzMxti+zqmPz4itqbpbcD4ND0R2FzK15XS+kr/LZIWSOqQ1NHd3b2P1TMzs97s94HciAggalCXSnlLIqItItrGjRtXq2KtiXhs36xx9jXoP5OGbUh/t6f0LcCkUr6WlNZXupmZ1dG+Bv1VQOUMnHnA7aX0c9NZPNOA3WkY6C5ghqQx6QDujJRmZmZ1NOCtlSXdApwKHCWpi+IsnMuBFZLmA08CZ6fsq4HTgE7gZeA8gIjYIenLwP0p36UR0fPg8JDzkEJzqXwfmy4/vcE1McvHgEE/Ij7Rx6LpveQN4Pw+ylkKLB1U7SwLDv5m9eMrcs3MMpLlk7OsOfUcfnPP34arZh5Kdk/fmpZP7TSrPQd9M7OMOOibmWXEY/rW9DzWb1Y7Dvo27PQ3zu8Ngln/PLxjZpYR9/RtROl5oZcv/LJ6Gg5nm2UR9IfDF2FmVg9ZBH3LT88NfV8bfu8BWG4c9C1rPjPIamE4jSY46JuV9LcR8PEBGwkc9M360VsPznsHVjGcevgVDvpmNeKNgQ0HDvpm+6mv3t5AGwEPF1kjOOib1Um1GwfwhqDZDcdhnQoHfbMm1tfegIeSGmM4B/sKB32zJlTtdQYDvd8bg9oYCcG+wkHfbASpZmPhvYbqjaRgX+GgbzYCDCY4DZS32r2EkbI3MRIDe38c9M2sV9UGw2ry7e8GpPwZgy2rr/lcOeib2ZCrZaDd141R7sG+YkQHfX/JZsOLf7NDzw9RMTPLiIO+mVlG6h70Jc2StEFSp6SF9f58M7Oc1TXoSzoAuAaYDUwFPiFpaj3rYGaWs3ofyD0R6IyIXwFIWg7MAR6rcz3MzOqmFqe11kq9g/5EYHNpvgs4qZxB0gJgQZp9UdKG/fzMo4Bn97OMoTYc6giuZy0NhzqC61lL/dZRV9T0s97R14KmO2UzIpYAS2pVnqSOiGirVXlDYTjUEVzPWhoOdQTXs5aapY71PpC7BZhUmm9JaWZmVgf1Dvr3A1MkTZZ0EDAXWFXnOpiZZauuwzsRsUfSXwB3AQcASyPi0SH+2JoNFQ2h4VBHcD1raTjUEVzPWmqKOioiGl0HMzOrE1+Ra2aWEQd9M7OMjNig36y3e5A0SdI9kh6T9KikC1L6WEntkjamv2OaoK4HSHpA0h1pfrKk+1Kb3poOxje6jqMlrZT0uKT1kk5u0rb8q/R9PyLpFkmHNEN7SloqabukR0ppvbafClen+q6TdEID6/i36TtfJ+k2SaNLyxalOm6QNLMedeyrnqVlF0oKSUel+Ya0JYzQoN/kt3vYA1wYEVOBacD5qW4LgTURMQVYk+Yb7QJgfWn+CuDKiDgG2AnMb0it9nYV8MOIOBZ4L0V9m6otJU0E/jvQFhHvoTiJYS7N0Z43ALN6pPXVfrOBKem1ALi2gXVsB94TEb8H/BuwCCD9luYCx6X3fDPFg0bVE0mTgBnAU6XkRrUlRMSIewEnA3eV5hcBixpdrz7qejvwEWADMCGlTQA2NLheLRQ/+A8BdwCiuJpwVG9t3KA6HgE8QTohoZTebG1ZuRJ9LMUZc3cAM5ulPYFW4JGB2g/4e+ATveWrdx17LPsj4OY0vddvneJMwZMb1ZYpbSVFh2QTcFSj23JE9vTp/XYPExtUlz5JagXeB9wHjI+IrWnRNmB8o+qVfAO4CHg9zR8J7IqIPWm+Gdp0MtANfDsNQ31L0mE0WVtGxBbgaxQ9va3AbmAtzdeeFX21X7P+rj4N/CBNN1UdJc0BtkTEQz0WNayeIzXoNz1JhwPfAT4bEc+Xl0Wx6W/YubSSPgpsj4i1japDlUYBJwDXRsT7gJfoMZTT6LYESGPicyg2UkcDh9HLMEAzaob264+kSyiGTG9udF16kvRm4GLgC42uS9lIDfpNfbsHSQdSBPybI+K7KfkZSRPS8gnA9kbVD/ggcKakTcByiiGeq4DRkioX9DVDm3YBXRFxX5pfSbERaKa2BPgw8EREdEfEq8B3Kdq42dqzoq/2a6rflaRPAR8FzkkbJ2iuOv4OxYb+ofRbagF+IentNLCeIzXoN+3tHiQJuB5YHxFfLy1aBcxL0/MoxvobIiIWRURLRLRStN3dEXEOcA/w8ZStoXUEiIhtwGZJ705J0ylu0900bZk8BUyT9Ob0/Vfq2VTtWdJX+60Czk1nnkwDdpeGgepK0iyK4cczI+Ll0qJVwFxJB0uaTHGg9OeNqGNEPBwRb4uI1vRb6gJOSP+3jWvLeh3gqPcLOI3iqP4vgUsaXZ9SvU6h2F1eBzyYXqdRjJmvATYCPwbGNrquqb6nAnek6XdS/IA6gX8GDm6C+h0PdKT2/B4wphnbEvgS8DjwCHATcHAztCdwC8VxhlcpgtL8vtqP4mD+Nek39TDF2UiNqmMnxZh45Td0XSn/JamOG4DZjWzLHss38R8HchvSlhHh2zCYmeVkpA7vmJlZLxz0zcwy4qBvZpYRB30zs4w46JuZZcRB38wsIw76ZmYZ+f+ZIAdovR84cAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장의 최단 길이, 최장 길이, 평균 길이를 구한 후 문장 길이분포를 막대그래프로 표현해주는 소스\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in data: \n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(data))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in data:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e525def1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아\n",
      "잼\n",
      "1\n",
      "4\n",
      "굿\n",
      "짱\n",
      "휴\n",
      ".\n",
      "음\n",
      "?\n",
      "ㅎ\n",
      "ㅋ\n",
      "즐\n",
      "♥\n",
      "굳\n",
      "네\n",
      "ㅇ\n",
      "k\n",
      "ㅠ\n",
      "쒯\n",
      "♬\n",
      "토\n",
      "O\n",
      "똥\n",
      "z\n",
      "헐\n",
      "삼\n",
      "꽝\n",
      "!\n",
      "풉\n",
      "ㅅ\n",
      "왜\n",
      "ㄴ\n",
      "쉣\n",
      "봐\n",
      "뿌\n",
      "ㅜ\n",
      "♡\n",
      "ㅁ\n",
      "0\n",
      "ㅉ\n",
      "d\n",
      "흥\n",
      "乃\n",
      "찜\n",
      "귯\n",
      "린\n",
      "시\n",
      "ㅗ\n",
      "a\n",
      "c\n",
      "흠\n",
      "웅\n",
      "ㅣ\n",
      "오\n",
      "9\n",
      "쩜\n",
      "애\n",
      "헝\n",
      "쨩\n",
      "f\n",
      "움\n",
      "ㄳ\n",
      "업\n",
      "헉\n",
      "군\n",
      "b\n",
      ";\n",
      "g\n",
      "올\n",
      "걍\n",
      "허\n",
      "-\n",
      "쀍\n",
      "로\n",
      "ㄹ\n",
      "ㅂ\n",
      "갑\n",
      "즛\n",
      "킥\n",
      "함\n",
      "진\n",
      "ㅡ\n",
      "잠\n",
      "곧\n",
      "ㅍ\n",
      "h\n",
      "·\n",
      "캬\n",
      "ㅆ\n",
      ",\n",
      "풋\n",
      "ㄱ\n",
      "파\n",
      "ㄷ\n",
      "웩\n",
      "꺅\n",
      "욜\n",
      "ㅄ\n",
      "2\n",
      "핡\n",
      "-------------------------------------\n",
      "\"스폰으로 먹고사는 방송이라 어쩔수 없다고 하지만. 이건 그냥 비현실적인 자동차만;...독일3사&슈퍼카 홍보 프로그램도 아니구.대중적인 자동차 방송으로 이루어 졌으면 합니다. 보는내내 \"\"카탈로그 책자\"\"를 \"\"동영상으로 보여주는 방송\"\" 같아서 씁쓸하네요.!\"\n",
      "\"\"\"니 짓은 생각않고, 웬 복수!\"\"의 교훈이라! 그럼 \"\"서바이벌 액션\"\"으로 홍보하면 안되지! 초반 45분은 멋지게 열더니.. 억지 반전, 하드고어로 시간끌다가, 허둥지둥 화해로 끝내버리네. 90분 러닝타임에 엔딩자막만 11분 틀어주는 해괴망측한 영화~!\"\n",
      "\"2007.02.25_ 벌교의 한 국밥집_ 점심: \"\"갸는 첫째고, 저 놈은 우리 둘째~\"\" 재문: \"\"아줌마! 미안해~ 그냥.. 아줌마! 나 그 남방 잘 어울려ㅠ_ㅠ?\"\" 대식에게 복수하려던 1주일 전_ 대식의 엄마를 먼저 만났다. 사랑의 꽃남방도..^-^o\"\n"
     ]
    }
   ],
   "source": [
    "# 길이 체크 함수로 문장 길이 확인하기\n",
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "\n",
    "# 훈련 데이터 길이가 1인 문장 확인해보기            \n",
    "check_sentence_with_length(data, 1)\n",
    "print(\"-------------------------------------\")\n",
    "# 훈련 데이터 길이가 146인 문장 확인해보기            \n",
    "check_sentence_with_length(data, 146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50a055d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Index: 12\n",
      "Outlier Index: 13\n",
      "Outlier Index: 14\n",
      "Outlier Index: 15\n",
      "Outlier Index: 16\n",
      "Outlier Index: 17\n"
     ]
    }
   ],
   "source": [
    "# 길이 별로 확인이 필요해보이는 문장 확인하기\n",
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # 문장 내 단어의 개수가 5000을 초과하는 인덱스를 추출\n",
    "    if _sum > 5000:\n",
    "        print(\"Outlier Index:\", idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55f56d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아햏햏 아햏햏 아햏햏.\n",
      "단연 최고라고 할수있지\n",
      "용가리 진짜짱짱맨이다ㅋ\n",
      "나름 괜찮은 작품입니다\n",
      "정말 실망 스러웟음..\n",
      "무술인이 왜 총을드나?\n",
      "너무너무 훈훈하네요^^\n",
      "현실은 꿈, 꿈은 현실\n",
      "답없네, 뭐하는건지..\n",
      "엔딩이 넘 슬퍼요 :(\n",
      "감동감동감동의 도가니탕\n",
      "정말 최고의 영화...\n",
      "진짜 짜증나는 영화..\n",
      "상당히 재밌게 봤습니다\n",
      "영상미가 역시 최고네요\n",
      "감독ㅡㅡ다신영화찍지마라\n",
      "이런 영화가 참 좋다.\n",
      "정말 광해와 비슷한가?\n",
      "더빙이 똥이야 ....\n",
      "잠을 청할 수 있었다.\n",
      "나오코 진짜 집중안된다\n",
      "샬라샬라 나오다즁자쥬아\n",
      "지루하다.. 지루해..\n",
      "사과해요, 나한테!!!\n",
      "소재가 굉장히 신선했다\n",
      "솔직히 산만 하기만했다\n",
      "OST가 좋은 영화!!\n",
      "기적은 이미 일어났다.\n",
      "답을 알려고 하지마라.\n",
      "평점은 믿지마셈 재밌음\n",
      "재미 드럽게 없다ㅋㅋㅋ\n",
      "자식을 그렇게 때리냐?\n",
      "감동적이였고 좋았습니다\n",
      "울컥하는 사회현실 ㅠㅠ\n",
      "등장인물들 모두 짱~~\n",
      "막장드라마가 따로없구만\n",
      "말 필요엄따~~~~진정\n",
      "꿀잼 영화 추억이다ㅜㅜ\n",
      "맞추자 ㅍ?차븟ㅇㄱ디시\n",
      "순수하고 아름답다 :)\n",
      "변태적 성욕 자기합리화\n",
      "흠....나름 갠찬네요\n",
      "걍 10점 이라길래..\n",
      "실력이 필요없는 상황.\n",
      "감동과 웃음을 한방에!\n",
      "이거야 이거 ㅋㅋㅋㅋㅋ\n",
      "성동일딸 시르다...참\n",
      "평점알바들을 위해 1점\n",
      "볼만합니다 강추!!ㅋㅋ\n",
      "이거말고 겨울왕국을봐라\n",
      "좋은니다..^.,^~~\n",
      "2.3 (10자 제한)\n",
      "아무도 안달았네..ㄷㄷ\n",
      "엉성하고 어설프고...\n",
      "그냥 보통으로 보았다.\n",
      "너무 슬픈영화..울음ㅠ\n",
      "으리는 개뿔 ㅡ,.ㅡ^\n",
      "처음 본 에로 영화..\n",
      "평점 조정을 위해...\n",
      "그냥 쓰레기지 쓰레기~\n",
      "쵝오네요 최고 대박영화\n",
      "유전무죄 무전유죄!!!\n",
      "의외의 꿀잼 이였습니다\n",
      "어차피 우승은 송민호~\n",
      "이 때부터가 쓰레기였지\n",
      "완전 찝찝한 영화...\n",
      "이상형이 바뀌었습니다.\n",
      "역시 산드라블록 누님!\n",
      "결국 엄마가 죽인거네?\n",
      "그냥 그저 별시리...\n",
      "추천할만한 경제영화였음\n",
      "제대로 알아야할 역사임\n",
      "일본판이더재미있음...\n",
      "역시 재미있군요 >ㅁ<\n",
      "아깝다 나의 1점도ㅡㅡ\n",
      "마음이 따뜻해지는 영화\n",
      "죽었다. 참 재미없다.\n",
      "최고, 정말 최고다,,\n",
      "공유 보려고 보는 영화\n",
      "재밌습니다. 꿀잼 ㅋㅋ\n",
      "조정래와 임권택의 만남\n",
      "간만에쓰레기영화보네요ㅋ\n",
      "너무재밌게 봤어요...\n",
      "의미가 뭘까...///\n",
      "이건 범죄 수준이다..\n",
      "박평식-뚜껑열린다ㅋㅋㅋ\n",
      "볼수록 재밌는 마의!!\n",
      "짱~ 오늘 티비로 봤음\n",
      "말없이 눈물이 뚝뚝..\n",
      "이렇게 유쾌할수가ㅋㅋㅋ\n",
      "완죤 지루하고 재미없네\n",
      "보다가 나가는 영화??\n",
      "에휴..........\n",
      "재미도 없구만...에효\n",
      "옥보단 3D보다 쓰레기\n",
      "반전이 꽤나 신선했다.\n",
      "허접허접허접허접허접허접\n",
      "독특한 유머. 재밌다.\n",
      "좀 식상한 스릴러영화~\n",
      "하하하핳하햐하핯하핳하하\n",
      "이영화 어디서 보나요?\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(data, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8864160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 194543\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33/614249671.py:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터에서 중복 제거하기\n",
    "min_len= 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(data))  # set를 사용해서 중복을 제거\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3448db9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33/1021478995.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 110\n",
    "min_len = 1\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려보자 \n",
    "# 아래 나온 그래프는 최종 데이터 분포\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8569f8",
   "metadata": {},
   "source": [
    "### 네이버 영화리뷰 감정분석 코퍼스에 sentencepiece를 적용시킨 모델 학습하기\n",
    "\n",
    "- unigram과 bpe 타입 model 파일과 vocal 파일을 각각 하나씩 만들어서 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14001eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "# 디폴트 --model_type = 'unigram'\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=naver_review_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "\n",
    "# --model_type = 'bpe'\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_type=bpe --model_prefix=naver_review_spm_bpe --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "\n",
    "!ls -l naver_review_spm*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50adfcbb",
   "metadata": {},
   "source": [
    "#### Unigram 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentencepiece 모델이 잘 적용됐는지 확인해보기\n",
    "s_uni = spm.SentencePieceProcessor() \n",
    "s_uni.Load('naver_review_spm.model') # unigram 타입 model\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s_uni.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s_uni.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s_uni.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a80e52",
   "metadata": {},
   "source": [
    "#### BPE 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbaf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentencepiece 모델이 잘 적용됐는지 확인해보기\n",
    "s_bpe = spm.SentencePieceProcessor() \n",
    "s_bpe.Load('naver_review_spm_bpe.model') # bpe 타입 model\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s_bpe.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s_bpe.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s_bpe.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f9cd4",
   "metadata": {},
   "source": [
    "### 학습된 모델로 sp_tokenize() 메소드 구현하기\n",
    "\n",
    "#### Unigram 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize_uni(s_uni, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s_uni.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./naver_review_spm.vocab\", 'r') as f: # unigram 타입 vocab\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre', maxlen = 100)\n",
    "\n",
    "    return tensor, word_index, index_word\n",
    "\n",
    "#sp_tokenize(s, corpus) 사용예제로 확인해\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor_uni, word_index_uni, index_word_uni = sp_tokenize_uni(s_uni, my_corpus)\n",
    "print(tensor_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e87445",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_uni, word_index_uni, index_word_uni = sp_tokenize_uni(s_uni, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d921b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_uni.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8742b62",
   "metadata": {},
   "source": [
    "#### BPE 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49022f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0  724 2991 6301  566\n",
      "   827 6272]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0 1709 2339  330  320 6280  155 7630\n",
      "    14    7]]\n"
     ]
    }
   ],
   "source": [
    "def sp_tokenize_bpe(s_bpe, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s_bpe.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./naver_review_spm_bpe.vocab\", 'r') as f: # bpe 타입 vocab\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre', maxlen = 100)\n",
    "\n",
    "    return tensor, word_index, index_word\n",
    "\n",
    "#sp_tokenize(s, corpus) 사용예제로 확인해\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor_bpe, word_index_bpe, index_word_bpe = sp_tokenize_bpe(s_bpe, my_corpus)\n",
    "print(tensor_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4d013d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_bpe, word_index_bpe, index_word_bpe = sp_tokenize_bpe(s_bpe, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb765b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195339, 100)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_bpe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158c9c9",
   "metadata": {},
   "source": [
    "### 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정분석 모델을 재학습하기\n",
    "\n",
    "- Unigram 타입을 적용한 토크나이저를 적용하여 RNN 모델 학습해보자.\n",
    "- 합쳐진 데이터를 분할하고, 검증 데이터도 분할해주자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59742bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train = tensor_uni[:146182]\n",
    "X_test = tensor_uni[146182:]\n",
    "\n",
    "y_train = np.array(list(train_data['label']))\n",
    "y_test = np.array(list(test_data['label']))\n",
    "\n",
    "# validation set 50000건 분리\n",
    "x_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = 10000    \n",
    "word_vector_dim = 16\n",
    "\n",
    "model_rnn = keras.Sequential()\n",
    "model_rnn.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_rnn.add(keras.layers.LSTM(12))   \n",
    "model_rnn.add(keras.layers.Dense(8, activation='relu'))\n",
    "model_rnn.add(keras.layers.Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55148352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs = 50\n",
    "\n",
    "history_rnn = model_rnn.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf81c5",
   "metadata": {},
   "source": [
    "##### 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ec77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_rnn = model_rnn.evaluate(X_test, y_test, verbose=2)\n",
    "print(results_rnn)\n",
    "\n",
    "history_dict_rnn = history_rnn.history\n",
    "print(history_dict_rnn.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "# train과 val의 Loss\n",
    "acc_rnn = history_dict_rnn['accuracy']\n",
    "val_acc_rnn = history_dict_rnn['val_accuracy']\n",
    "loss_rnn = history_dict_rnn['loss']\n",
    "val_loss_rnn = history_dict_rnn['val_loss']\n",
    "\n",
    "epochs_rnn = range(1, len(acc_rnn) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"\n",
    "plt.plot(epochs_rnn, loss_rnn, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"\n",
    "plt.plot(epochs_rnn, val_loss_rnn, 'b', label='Validation loss')\n",
    "plt.title('RNN\\'s Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# train과 val의 accuracy\n",
    "plt.clf()  \n",
    "\n",
    "plt.plot(epochs_rnn, acc_rnn, 'bo', label='Training acc')\n",
    "plt.plot(epochs_rnn, val_acc_rnn, 'b', label='Validation acc')\n",
    "plt.title('RNN\\'s Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train = tensor_bpe[:146182]\n",
    "X_test = tensor_bpe[146182:]\n",
    "\n",
    "y_train = np.array(list(train_data['label']))\n",
    "y_test = np.array(list(test_data['label']))\n",
    "\n",
    "# validation set 50000건 분리\n",
    "x_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6158c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = 10000    \n",
    "word_vector_dim = 16\n",
    "\n",
    "model_rnn = keras.Sequential()\n",
    "model_rnn.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_rnn.add(keras.layers.LSTM(12))   \n",
    "model_rnn.add(keras.layers.Dense(8, activation='relu'))\n",
    "model_rnn.add(keras.layers.Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce381760",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs = 50\n",
    "\n",
    "history_rnn = model_rnn.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a3084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가하기\n",
    "results_rnn = model_rnn.evaluate(X_test, y_test, verbose=2)\n",
    "print(results_rnn)\n",
    "\n",
    "history_dict_rnn = history_rnn.history\n",
    "print(history_dict_rnn.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "# train과 val의 Loss\n",
    "acc_rnn = history_dict_rnn['accuracy']\n",
    "val_acc_rnn = history_dict_rnn['val_accuracy']\n",
    "loss_rnn = history_dict_rnn['loss']\n",
    "val_loss_rnn = history_dict_rnn['val_loss']\n",
    "\n",
    "epochs_rnn = range(1, len(acc_rnn) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"\n",
    "plt.plot(epochs_rnn, loss_rnn, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"\n",
    "plt.plot(epochs_rnn, val_loss_rnn, 'b', label='Validation loss')\n",
    "plt.title('RNN\\'s Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# train과 val의 accuracy\n",
    "plt.clf()  \n",
    "\n",
    "plt.plot(epochs_rnn, acc_rnn, 'bo', label='Training acc')\n",
    "plt.plot(epochs_rnn, val_acc_rnn, 'b', label='Validation acc')\n",
    "plt.title('RNN\\'s Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b595c",
   "metadata": {},
   "source": [
    "### KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
    "\n",
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전word_to_index 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d446c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다'] \n",
    "num_words = 10000\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f8368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수\n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수\n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d1bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  모델 구성을 위한 데이터 분석 및 가공을 해주자.\n",
    "\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(X_train), len(X_test)))\n",
    "\n",
    "# 데이터셋 내 문장 길이 분포 파악\n",
    "print(X_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(X_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(X_train[1]))\n",
    "\n",
    "print(get_decoded_sentence(X_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적절한 최대 문장 길이를 지정\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 최대 길이를 (평균 + 2*표준편차)로 설정  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174692a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 작업\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ab1c6",
   "metadata": {},
   "source": [
    "- RNN 모델 구성 및 검증 데이터셋을 구성해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20870348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  validation set 구성\n",
    "X_val = X_train[:50000]   \n",
    "y_val = y_train[:50000]\n",
    "\n",
    "# validation set을 제외한 나머지\n",
    "partial_X_train = X_train[50000:]  \n",
    "partial_y_train = y_train[50000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a49cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = 10000    \n",
    "word_vector_dim = 16\n",
    "\n",
    "model_rnn = keras.Sequential()\n",
    "model_rnn.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_rnn.add(keras.layers.LSTM(12))   \n",
    "model_rnn.add(keras.layers.Dense(8, activation='relu'))\n",
    "model_rnn.add(keras.layers.Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04680040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs = 50\n",
    "\n",
    "history_rnn = model_rnn.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c504f4",
   "metadata": {},
   "source": [
    "##### 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd855be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rnn = model_rnn.evaluate(X_test, y_test, verbose=2)\n",
    "print(results_rnn)\n",
    "\n",
    "history_dict_rnn = history_rnn.history\n",
    "print(history_dict_rnn.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "# train과 val의 Loss\n",
    "acc_rnn = history_dict_rnn['accuracy']\n",
    "val_acc_rnn = history_dict_rnn['val_accuracy']\n",
    "loss_rnn = history_dict_rnn['loss']\n",
    "val_loss_rnn = history_dict_rnn['val_loss']\n",
    "\n",
    "epochs_rnn = range(1, len(acc_rnn) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"\n",
    "plt.plot(epochs_rnn, loss_rnn, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"\n",
    "plt.plot(epochs_rnn, val_loss_rnn, 'b', label='Validation loss')\n",
    "plt.title('RNN\\'s Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# train과 val의 accuracy\n",
    "plt.clf()  \n",
    "\n",
    "plt.plot(epochs_rnn, acc_rnn, 'bo', label='Training acc')\n",
    "plt.plot(epochs_rnn, val_acc_rnn, 'b', label='Validation acc')\n",
    "plt.title('RNN\\'s Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c276f6c",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "- [ ]  **4. 프로젝트에 대한 회고가 상세히 기록 되어 있나요? (회고, 정리)**\n",
    "    - [ ]  배운 점 : 전처리, 토큰화, 워드임베딩 기법 등을 배울수 있었다.\n",
    "    - [ ]  아쉬운 점 : 우도? 이런거 계산하는 거 이해하기 어려움\n",
    "    - [ ]  느낀 점 : 매일매일 꾸준히 하자\n",
    "    - [ ]  어려웠던 점 : 링크 논문 을 읽지 못하였다 .. 시간관계상 저녁에 읽어볼까? 생각함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83b449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
